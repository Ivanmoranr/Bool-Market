{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-02 12:19:09.228797: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-02 12:19:09.230156: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-02 12:19:09.260911: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-02 12:19:09.261954: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-02 12:19:09.780493: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from synthetic_data import *\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from get_real_data import *\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Masking, Conv1D, Flatten, MaxPooling1D, Input, Concatenate, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import regularizers\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ris_wedg, y_ris_wedg, X_fal_wedg, y_fal_wedg, X_d_top, y_d_top, X_d_bottom, y_d_bottom = get_X_y(noise=True, general=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, y1, X2, y2, X3, y3, X4, y4 = get_real_X_y(noise = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_ris_wedg + X1\n",
    "y = y_ris_wedg + y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehotencode(y_synth):\n",
    "    y_synth = np.array(y_synth)\n",
    "    start = y_synth[:,0]\n",
    "    end = y_synth[:,1]\n",
    "    pattern = y_synth[:,2]\n",
    "    mapping = {\n",
    "        0: [0, 0, 0, 0],\n",
    "        1: [0, 0, 0, 1],\n",
    "        2: [0, 0, 1, 0],\n",
    "        3: [0, 1, 0, 0],\n",
    "        4: [1, 0, 0, 0]\n",
    "    }\n",
    "    mapped_values = [list(mapping[val]) for val in pattern]\n",
    "    y_s = (np.column_stack((start, end, mapped_values)))\n",
    "    return y_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preprocessed = onehotencode(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_preprocessed, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_dates = y_train[:,:2]\n",
    "y_test_dates = y_test[:,:2]\n",
    "y_train_p = y_train[:,2:]\n",
    "y_test_p = y_test[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed=[]\n",
    "scale={}\n",
    "for i in range(len(X_train)):\n",
    "    open_scaler_i = StandardScaler()\n",
    "    X_train_processed.append(open_scaler_i.fit_transform(X_train[i]))\n",
    "    scale[f\"open_scaler_{len(X_train[i])}\"] = open_scaler_i\n",
    "\n",
    "X_test_processed=[]\n",
    "scale={}\n",
    "for i in range(len(X_test)):\n",
    "    open_scaler_i = StandardScaler()\n",
    "    X_test_processed.append(open_scaler_i.fit_transform(X_test[i]))\n",
    "    scale[f\"open_scaler_{len(X_test[i])}\"] = open_scaler_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_preprocessed = pad_sequences(X_train_processed,maxlen = 502, dtype='float32', padding='post', value=-1)\n",
    "X_test_preprocessed = pad_sequences(X_test_processed, maxlen = 502, dtype='float32', padding='post', value=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_preprocessed = tf.convert_to_tensor(X_train_preprocessed, np.float32)\n",
    "y_train = tf.convert_to_tensor(y_train, np.int16)\n",
    "\n",
    "display(type(X_train_preprocessed))\n",
    "display(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_regression_model_1():\n",
    "    # Input layer\n",
    "    # Input layer\n",
    "    input_shape = X_train_preprocessed.shape[1:]\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "\n",
    "    # Shared layers\n",
    "    masked_input = Masking(mask_value=-1)(input_layer)\n",
    "    conv1d_1 = Conv1D(32, activation='relu', kernel_size=3, kernel_regularizer=regularizers.L1L2(l1=1e-3, l2=1e-3))(masked_input)\n",
    "    maxpool_1 = MaxPooling1D(pool_size=2)(conv1d_1)\n",
    "    conv1d_2 = Conv1D(32, activation='relu', kernel_size=3)(maxpool_1)\n",
    "    \n",
    "    flatten = Flatten()(conv1d_2)\n",
    "    dense_1 = Dense(units=192, activation='relu')(flatten)\n",
    "    dropout_1 = Dropout(rate=0.5)(dense_1)\n",
    "    dense_2 = Dense(units=128, activation='relu')(dropout_1)\n",
    "    dropout_2 = Dropout(rate=0.5)(dense_2)\n",
    "    dense_3 = Dense(units=64, activation='relu')(dropout_2)\n",
    "    dropout_3 = Dropout(rate=0.5)(dense_3)\n",
    "    dense_4 = Dense(units=32, activation='relu')(dropout_3)\n",
    "    \n",
    "\n",
    "    # Classification output\n",
    "    classification_output = Dense(units=4, activation='softmax', name='classification_output')(dense_4)\n",
    "\n",
    "    # Combine input and classification output for regression\n",
    "    regression_input = Concatenate()([dense_4, classification_output])\n",
    "\n",
    "    # Regression output\n",
    "    regression_output = Dense(units=2, activation='linear', name='regression_output')(regression_input)\n",
    "\n",
    "    # Create the combined model\n",
    "    model = Model(inputs=input_layer, outputs=[classification_output, regression_output])\n",
    "\n",
    "    # Compile the model with appropriate loss functions and metrics for each output\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss={'classification_output': 'categorical_crossentropy', 'regression_output': 'mean_squared_error'},\n",
    "                  metrics={'classification_output': 'accuracy', 'regression_output': 'mae'})\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 11745.4170 - classification_output_loss: 20.8179 - regression_output_loss: 11724.5410 - classification_output_accuracy: 0.0342 - regression_output_mae: 70.1412 - val_loss: 8405.0840 - val_classification_output_loss: 23.4905 - val_regression_output_loss: 8381.5352 - val_classification_output_accuracy: 0.0000e+00 - val_regression_output_mae: 61.9423\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 8950.5566 - classification_output_loss: 23.8730 - regression_output_loss: 8926.6260 - classification_output_accuracy: 0.0372 - regression_output_mae: 65.9496 - val_loss: 7982.2329 - val_classification_output_loss: 15.8551 - val_regression_output_loss: 7966.3213 - val_classification_output_accuracy: 0.0000e+00 - val_regression_output_mae: 60.8304\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 16ms/step - loss: 8123.4951 - classification_output_loss: 10.9001 - regression_output_loss: 8112.5371 - classification_output_accuracy: 0.1397 - regression_output_mae: 63.2161 - val_loss: 7334.5923 - val_classification_output_loss: 3.8965 - val_regression_output_loss: 7330.6387 - val_classification_output_accuracy: 0.0000e+00 - val_regression_output_mae: 59.4957\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 7932.9595 - classification_output_loss: 3.4782 - regression_output_loss: 7929.4253 - classification_output_accuracy: 0.3176 - regression_output_mae: 63.0489 - val_loss: 6958.9004 - val_classification_output_loss: 0.0492 - val_regression_output_loss: 6958.7949 - val_classification_output_accuracy: 0.4739 - val_regression_output_mae: 57.5602\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 7123.8872 - classification_output_loss: 2.5456 - regression_output_loss: 7121.2837 - classification_output_accuracy: 0.3839 - regression_output_mae: 59.4845 - val_loss: 6580.0249 - val_classification_output_loss: 0.0010 - val_regression_output_loss: 6579.9658 - val_classification_output_accuracy: 0.4819 - val_regression_output_mae: 54.8349\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 6094.9663 - classification_output_loss: 1.6708 - regression_output_loss: 6093.2368 - classification_output_accuracy: 0.4010 - regression_output_mae: 54.7293 - val_loss: 5803.4297 - val_classification_output_loss: 1.5516e-04 - val_regression_output_loss: 5803.3721 - val_classification_output_accuracy: 0.4819 - val_regression_output_mae: 53.8379\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 5630.9761 - classification_output_loss: 0.6482 - regression_output_loss: 5630.2700 - classification_output_accuracy: 0.4503 - regression_output_mae: 52.2706 - val_loss: 5110.0420 - val_classification_output_loss: 0.0020 - val_regression_output_loss: 5109.9819 - val_classification_output_accuracy: 0.4819 - val_regression_output_mae: 49.7904\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 5126.9307 - classification_output_loss: 0.9362 - regression_output_loss: 5125.9360 - classification_output_accuracy: 0.4352 - regression_output_mae: 49.2924 - val_loss: 5427.3872 - val_classification_output_loss: 0.0165 - val_regression_output_loss: 5427.3130 - val_classification_output_accuracy: 0.4819 - val_regression_output_mae: 49.8013\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 4750.1235 - classification_output_loss: 1.1858 - regression_output_loss: 4748.8799 - classification_output_accuracy: 0.4261 - regression_output_mae: 46.9936 - val_loss: 4583.9834 - val_classification_output_loss: 0.0306 - val_regression_output_loss: 4583.8940 - val_classification_output_accuracy: 0.4819 - val_regression_output_mae: 46.3202\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 4370.0303 - classification_output_loss: 1.4059 - regression_output_loss: 4368.5654 - classification_output_accuracy: 0.4050 - regression_output_mae: 45.2941 - val_loss: 5200.8633 - val_classification_output_loss: 0.0290 - val_regression_output_loss: 5200.7754 - val_classification_output_accuracy: 0.4900 - val_regression_output_mae: 47.9385\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 4462.7656 - classification_output_loss: 0.8242 - regression_output_loss: 4461.8818 - classification_output_accuracy: 0.4342 - regression_output_mae: 44.3861 - val_loss: 4463.0044 - val_classification_output_loss: 0.0191 - val_regression_output_loss: 4462.9268 - val_classification_output_accuracy: 0.4900 - val_regression_output_mae: 44.3692\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 4380.0488 - classification_output_loss: 0.7242 - regression_output_loss: 4379.2651 - classification_output_accuracy: 0.4462 - regression_output_mae: 42.7913 - val_loss: 4548.0244 - val_classification_output_loss: 0.0322 - val_regression_output_loss: 4547.9331 - val_classification_output_accuracy: 0.4980 - val_regression_output_mae: 44.6786\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 3841.8401 - classification_output_loss: 0.3971 - regression_output_loss: 3841.3845 - classification_output_accuracy: 0.4623 - regression_output_mae: 41.2032 - val_loss: 4132.3975 - val_classification_output_loss: 0.0326 - val_regression_output_loss: 4132.3057 - val_classification_output_accuracy: 0.5100 - val_regression_output_mae: 43.2219\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 3808.2417 - classification_output_loss: 0.3634 - regression_output_loss: 3807.8186 - classification_output_accuracy: 0.4693 - regression_output_mae: 40.7570 - val_loss: 4713.6196 - val_classification_output_loss: 0.0226 - val_regression_output_loss: 4713.5371 - val_classification_output_accuracy: 0.4980 - val_regression_output_mae: 43.7834\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 3408.9019 - classification_output_loss: 0.5022 - regression_output_loss: 3408.3401 - classification_output_accuracy: 0.4613 - regression_output_mae: 38.5537 - val_loss: 5048.4834 - val_classification_output_loss: 0.0306 - val_regression_output_loss: 5048.3931 - val_classification_output_accuracy: 0.5100 - val_regression_output_mae: 44.8926\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 3341.8516 - classification_output_loss: 0.4622 - regression_output_loss: 3341.3296 - classification_output_accuracy: 0.4774 - regression_output_mae: 37.8775 - val_loss: 4618.7305 - val_classification_output_loss: 0.0358 - val_regression_output_loss: 4618.6353 - val_classification_output_accuracy: 0.5221 - val_regression_output_mae: 42.2845\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 3334.7546 - classification_output_loss: 0.8065 - regression_output_loss: 3333.8884 - classification_output_accuracy: 0.4583 - regression_output_mae: 37.3407 - val_loss: 3979.7854 - val_classification_output_loss: 0.0454 - val_regression_output_loss: 3979.6802 - val_classification_output_accuracy: 0.5181 - val_regression_output_mae: 39.2503\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 2806.5703 - classification_output_loss: 0.3704 - regression_output_loss: 2806.1392 - classification_output_accuracy: 0.4724 - regression_output_mae: 35.2420 - val_loss: 3621.2629 - val_classification_output_loss: 0.0375 - val_regression_output_loss: 3621.1648 - val_classification_output_accuracy: 0.5181 - val_regression_output_mae: 38.8891\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 2893.9675 - classification_output_loss: 0.1657 - regression_output_loss: 2893.7417 - classification_output_accuracy: 0.5015 - regression_output_mae: 35.3845 - val_loss: 3640.6929 - val_classification_output_loss: 0.0434 - val_regression_output_loss: 3640.5889 - val_classification_output_accuracy: 0.5301 - val_regression_output_mae: 37.5827\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 2966.8223 - classification_output_loss: 0.1806 - regression_output_loss: 2966.5813 - classification_output_accuracy: 0.4945 - regression_output_mae: 36.2230 - val_loss: 2696.9272 - val_classification_output_loss: 0.0252 - val_regression_output_loss: 2696.8411 - val_classification_output_accuracy: 0.5100 - val_regression_output_mae: 34.9367\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 2716.9297 - classification_output_loss: 0.1557 - regression_output_loss: 2716.7139 - classification_output_accuracy: 0.5146 - regression_output_mae: 33.7125 - val_loss: 3774.4233 - val_classification_output_loss: 0.0263 - val_regression_output_loss: 3774.3369 - val_classification_output_accuracy: 0.5663 - val_regression_output_mae: 37.5387\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 2666.9602 - classification_output_loss: 0.2780 - regression_output_loss: 2666.6218 - classification_output_accuracy: 0.4975 - regression_output_mae: 32.8900 - val_loss: 3101.9243 - val_classification_output_loss: 0.0318 - val_regression_output_loss: 3101.8318 - val_classification_output_accuracy: 0.5341 - val_regression_output_mae: 34.8731\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 2327.2588 - classification_output_loss: 0.2587 - regression_output_loss: 2326.9399 - classification_output_accuracy: 0.5116 - regression_output_mae: 31.3671 - val_loss: 2564.2754 - val_classification_output_loss: 0.0187 - val_regression_output_loss: 2564.1958 - val_classification_output_accuracy: 0.5261 - val_regression_output_mae: 32.4531\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 2320.2383 - classification_output_loss: 0.0626 - regression_output_loss: 2320.1150 - classification_output_accuracy: 0.5266 - regression_output_mae: 31.1261 - val_loss: 3840.4524 - val_classification_output_loss: 0.0316 - val_regression_output_loss: 3840.3599 - val_classification_output_accuracy: 0.5622 - val_regression_output_mae: 36.6487\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 2223.6675 - classification_output_loss: 0.1140 - regression_output_loss: 2223.4927 - classification_output_accuracy: 0.5256 - regression_output_mae: 29.9197 - val_loss: 3218.0171 - val_classification_output_loss: 0.0402 - val_regression_output_loss: 3217.9158 - val_classification_output_accuracy: 0.6345 - val_regression_output_mae: 35.0839\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 2091.9890 - classification_output_loss: 0.1441 - regression_output_loss: 2091.7842 - classification_output_accuracy: 0.5116 - regression_output_mae: 29.5625 - val_loss: 2855.1836 - val_classification_output_loss: 0.0172 - val_regression_output_loss: 2855.1055 - val_classification_output_accuracy: 0.5502 - val_regression_output_mae: 32.2767\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 2374.7817 - classification_output_loss: 0.0850 - regression_output_loss: 2374.6353 - classification_output_accuracy: 0.5116 - regression_output_mae: 30.0532 - val_loss: 2806.7534 - val_classification_output_loss: 0.0492 - val_regression_output_loss: 2806.6428 - val_classification_output_accuracy: 0.5823 - val_regression_output_mae: 32.3957\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 1937.1599 - classification_output_loss: 0.0781 - regression_output_loss: 1937.0206 - classification_output_accuracy: 0.5146 - regression_output_mae: 29.1419 - val_loss: 3022.4678 - val_classification_output_loss: 0.0267 - val_regression_output_loss: 3022.3801 - val_classification_output_accuracy: 0.5944 - val_regression_output_mae: 32.9619\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 2146.0259 - classification_output_loss: 0.0333 - regression_output_loss: 2145.9314 - classification_output_accuracy: 0.5266 - regression_output_mae: 28.6864 - val_loss: 3710.8896 - val_classification_output_loss: 0.0337 - val_regression_output_loss: 3710.7947 - val_classification_output_accuracy: 0.5904 - val_regression_output_mae: 34.6398\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 2267.9424 - classification_output_loss: 0.0182 - regression_output_loss: 2267.8630 - classification_output_accuracy: 0.5337 - regression_output_mae: 29.9858 - val_loss: 3222.3506 - val_classification_output_loss: 0.0220 - val_regression_output_loss: 3222.2673 - val_classification_output_accuracy: 0.5502 - val_regression_output_mae: 34.0676\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 2060.9163 - classification_output_loss: 0.0243 - regression_output_loss: 2060.8311 - classification_output_accuracy: 0.5387 - regression_output_mae: 28.9087 - val_loss: 2911.3911 - val_classification_output_loss: 0.0193 - val_regression_output_loss: 2911.3108 - val_classification_output_accuracy: 0.5703 - val_regression_output_mae: 32.5080\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 1948.6302 - classification_output_loss: 0.0177 - regression_output_loss: 1948.5510 - classification_output_accuracy: 0.5528 - regression_output_mae: 27.5642 - val_loss: 2622.5566 - val_classification_output_loss: 0.0069 - val_regression_output_loss: 2622.4885 - val_classification_output_accuracy: 0.5542 - val_regression_output_mae: 31.3215\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 2013.7521 - classification_output_loss: 0.0195 - regression_output_loss: 2013.6711 - classification_output_accuracy: 0.5317 - regression_output_mae: 28.2923 - val_loss: 3110.7031 - val_classification_output_loss: 0.0304 - val_regression_output_loss: 3110.6113 - val_classification_output_accuracy: 0.5663 - val_regression_output_mae: 34.1335\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(patience = 10, restore_best_weights=True)\n",
    "#lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-6)\n",
    "\n",
    "model_3 = conditional_regression_model_1()\n",
    "\n",
    "history = model_3.fit(\n",
    "    x=X_train_preprocessed,\n",
    "    y={'classification_output': y_train_p, 'regression_output': y_train_dates},\n",
    "    validation_split = 0.2,\n",
    "    shuffle = True,\n",
    "    batch_size=32,\n",
    "    epochs = 50,\n",
    "    callbacks = [es],\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 6ms/step - loss: 3044.9692 - classification_output_loss: 0.0180 - regression_output_loss: 3044.8901 - classification_output_accuracy: 0.5897 - regression_output_mae: 34.9237\n"
     ]
    }
   ],
   "source": [
    "evaluation_3 = model_3.evaluate(\n",
    "    x=X_test_preprocessed,  # Test input data\n",
    "    y={'classification_output': y_test_p, 'regression_output': y_test_dates},  # Dictionary of test labels\n",
    "    verbose=1  # Set to 1 for progress updates during evaluation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bool",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
