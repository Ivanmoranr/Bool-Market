{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-02 12:37:27.534657: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-02 12:37:27.536098: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-02 12:37:27.559714: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-02 12:37:27.560630: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-02 12:37:28.053066: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from synthetic_data import *\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from get_real_data import *\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Masking, Conv1D, Flatten, MaxPooling1D, Input, Concatenate, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import regularizers\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ris_wedg, y_ris_wedg, X_fal_wedg, y_fal_wedg, X_d_top, y_d_top, X_d_bottom, y_d_bottom = get_X_y(noise=True, general=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, y1, X2, y2, X3, y3, X4, y4 = get_real_X_y(noise = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = X_ris_wedg + X1\n",
    "#y = y_ris_wedg + y1\n",
    "X=X1\n",
    "y=y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehotencode(y_synth):\n",
    "    y_synth = np.array(y_synth)\n",
    "    start = y_synth[:,0]\n",
    "    end = y_synth[:,1]\n",
    "    pattern = y_synth[:,2]\n",
    "    mapping = {\n",
    "        0: [0, 0, 0, 0],\n",
    "        1: [0, 0, 0, 1],\n",
    "        2: [0, 0, 1, 0],\n",
    "        3: [0, 1, 0, 0],\n",
    "        4: [1, 0, 0, 0]\n",
    "    }\n",
    "    mapped_values = [list(mapping[val]) for val in pattern]\n",
    "    y_s = (np.column_stack((start, end, mapped_values)))\n",
    "    return y_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preprocessed = onehotencode(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_preprocessed, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_dates = y_train[:,:2]\n",
    "y_test_dates = y_test[:,:2]\n",
    "y_train_p = y_train[:,2:]\n",
    "y_test_p = y_test[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed=[]\n",
    "scale={}\n",
    "for i in range(len(X_train)):\n",
    "    open_scaler_i = StandardScaler()\n",
    "    X_train_processed.append(open_scaler_i.fit_transform(X_train[i]))\n",
    "    scale[f\"open_scaler_{len(X_train[i])}\"] = open_scaler_i\n",
    "\n",
    "X_test_processed=[]\n",
    "scale={}\n",
    "for i in range(len(X_test)):\n",
    "    open_scaler_i = StandardScaler()\n",
    "    X_test_processed.append(open_scaler_i.fit_transform(X_test[i]))\n",
    "    scale[f\"open_scaler_{len(X_test[i])}\"] = open_scaler_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_preprocessed = pad_sequences(X_train_processed,maxlen = 502, dtype='float32', padding='post', value=-1)\n",
    "X_test_preprocessed = pad_sequences(X_test_processed, maxlen = 502, dtype='float32', padding='post', value=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_preprocessed = tf.convert_to_tensor(X_train_preprocessed, np.float32)\n",
    "y_train = tf.convert_to_tensor(y_train, np.int16)\n",
    "\n",
    "display(type(X_train_preprocessed))\n",
    "display(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_regression_model_1():\n",
    "    # Input layer\n",
    "    # Input layer\n",
    "    input_shape = X_train_preprocessed.shape[1:]\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "\n",
    "    # Shared layers\n",
    "    masked_input = Masking(mask_value=-1)(input_layer)\n",
    "    conv1d_1 = Conv1D(32, activation='relu', kernel_size=3, kernel_regularizer=regularizers.L1L2(l1=1e-3, l2=1e-3))(masked_input)\n",
    "    maxpool_1 = MaxPooling1D(pool_size=2)(conv1d_1)\n",
    "    conv1d_2 = Conv1D(32, activation='relu', kernel_size=3)(maxpool_1)\n",
    "    \n",
    "    flatten = Flatten()(conv1d_2)\n",
    "    dense_1 = Dense(units=192, activation='relu')(flatten)\n",
    "    dropout_1 = Dropout(rate=0.5)(dense_1)\n",
    "    dense_2 = Dense(units=128, activation='relu')(dropout_1)\n",
    "    dropout_2 = Dropout(rate=0.5)(dense_2)\n",
    "    dense_3 = Dense(units=64, activation='relu')(dropout_2)\n",
    "    dropout_3 = Dropout(rate=0.5)(dense_3)\n",
    "    dense_4 = Dense(units=32, activation='relu')(dropout_3)\n",
    "    \n",
    "\n",
    "    # Classification output\n",
    "    classification_output = Dense(units=4, activation='softmax', name='classification_output')(dense_4)\n",
    "\n",
    "    # Combine input and classification output for regression\n",
    "    regression_input = Concatenate()([dense_4, classification_output])\n",
    "\n",
    "    # Regression output\n",
    "    regression_output = Dense(units=2, activation='linear', name='regression_output')(regression_input)\n",
    "\n",
    "    # Create the combined model\n",
    "    model = Model(inputs=input_layer, outputs=[classification_output, regression_output])\n",
    "\n",
    "    # Compile the model with appropriate loss functions and metrics for each output\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss={'classification_output': 'categorical_crossentropy', 'regression_output': 'mean_squared_error'},\n",
    "                  metrics={'classification_output': 'accuracy', 'regression_output': 'mae'})\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 21ms/step - loss: 5851.1411 - classification_output_loss: 20.3038 - regression_output_loss: 5830.7856 - classification_output_accuracy: 0.3994 - regression_output_mae: 49.2488 - val_loss: 2138.2129 - val_classification_output_loss: 29.4428 - val_regression_output_loss: 2108.7168 - val_classification_output_accuracy: 0.5730 - val_regression_output_mae: 36.5116\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 2442.0750 - classification_output_loss: 24.8166 - regression_output_loss: 2417.2051 - classification_output_accuracy: 0.3924 - regression_output_mae: 34.5611 - val_loss: 1783.9761 - val_classification_output_loss: 12.9989 - val_regression_output_loss: 1770.9238 - val_classification_output_accuracy: 0.5730 - val_regression_output_mae: 30.6551\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 2136.2925 - classification_output_loss: 9.7905 - regression_output_loss: 2126.4487 - classification_output_accuracy: 0.4388 - regression_output_mae: 32.0962 - val_loss: 1725.0411 - val_classification_output_loss: 7.1440 - val_regression_output_loss: 1717.8441 - val_classification_output_accuracy: 0.5730 - val_regression_output_mae: 30.3614\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 2215.3105 - classification_output_loss: 4.3115 - regression_output_loss: 2210.9463 - classification_output_accuracy: 0.4360 - regression_output_mae: 32.7753 - val_loss: 2006.5079 - val_classification_output_loss: 1.1382 - val_regression_output_loss: 2005.3169 - val_classification_output_accuracy: 0.4663 - val_regression_output_mae: 31.4961\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 2007.3611 - classification_output_loss: 2.2651 - regression_output_loss: 2005.0427 - classification_output_accuracy: 0.4754 - regression_output_mae: 31.3004 - val_loss: 1512.1533 - val_classification_output_loss: 0.5099 - val_regression_output_loss: 1511.5906 - val_classification_output_accuracy: 0.4045 - val_regression_output_mae: 28.8345\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 1652.9661 - classification_output_loss: 1.6899 - regression_output_loss: 1651.2236 - classification_output_accuracy: 0.4726 - regression_output_mae: 29.1338 - val_loss: 1540.1298 - val_classification_output_loss: 0.0255 - val_regression_output_loss: 1540.0513 - val_classification_output_accuracy: 0.4270 - val_regression_output_mae: 27.5501\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 2012.9805 - classification_output_loss: 1.7538 - regression_output_loss: 2011.1736 - classification_output_accuracy: 0.4557 - regression_output_mae: 30.5484 - val_loss: 1524.3682 - val_classification_output_loss: 0.0259 - val_regression_output_loss: 1524.2896 - val_classification_output_accuracy: 0.4270 - val_regression_output_mae: 28.0964\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 1583.7432 - classification_output_loss: 0.5510 - regression_output_loss: 1583.1394 - classification_output_accuracy: 0.5091 - regression_output_mae: 28.1050 - val_loss: 1434.4719 - val_classification_output_loss: 0.0184 - val_regression_output_loss: 1434.4010 - val_classification_output_accuracy: 0.4270 - val_regression_output_mae: 27.2520\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 1745.7288 - classification_output_loss: 0.7498 - regression_output_loss: 1744.9261 - classification_output_accuracy: 0.4684 - regression_output_mae: 29.0377 - val_loss: 1343.2791 - val_classification_output_loss: 0.0112 - val_regression_output_loss: 1343.2152 - val_classification_output_accuracy: 0.4270 - val_regression_output_mae: 26.2748\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 1522.4437 - classification_output_loss: 1.3150 - regression_output_loss: 1521.0762 - classification_output_accuracy: 0.4585 - regression_output_mae: 28.0512 - val_loss: 1337.0817 - val_classification_output_loss: 0.0206 - val_regression_output_loss: 1337.0084 - val_classification_output_accuracy: 0.4270 - val_regression_output_mae: 26.1384\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 1396.6301 - classification_output_loss: 0.7796 - regression_output_loss: 1395.7977 - classification_output_accuracy: 0.4782 - regression_output_mae: 26.4825 - val_loss: 1462.0151 - val_classification_output_loss: 0.0507 - val_regression_output_loss: 1461.9119 - val_classification_output_accuracy: 0.4213 - val_regression_output_mae: 26.1370\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 1349.5164 - classification_output_loss: 1.5196 - regression_output_loss: 1347.9441 - classification_output_accuracy: 0.4262 - regression_output_mae: 25.8385 - val_loss: 1390.6923 - val_classification_output_loss: 0.0607 - val_regression_output_loss: 1390.5790 - val_classification_output_accuracy: 0.4270 - val_regression_output_mae: 26.4890\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 1671.7321 - classification_output_loss: 0.9304 - regression_output_loss: 1670.7491 - classification_output_accuracy: 0.4543 - regression_output_mae: 28.3383 - val_loss: 1241.0073 - val_classification_output_loss: 0.0482 - val_regression_output_loss: 1240.9067 - val_classification_output_accuracy: 0.4270 - val_regression_output_mae: 24.9943\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 1400.5350 - classification_output_loss: 0.8174 - regression_output_loss: 1399.6650 - classification_output_accuracy: 0.4726 - regression_output_mae: 26.1590 - val_loss: 1303.4546 - val_classification_output_loss: 0.0311 - val_regression_output_loss: 1303.3708 - val_classification_output_accuracy: 0.4270 - val_regression_output_mae: 25.2523\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 1322.9871 - classification_output_loss: 0.3166 - regression_output_loss: 1322.6178 - classification_output_accuracy: 0.4965 - regression_output_mae: 24.5671 - val_loss: 1219.9764 - val_classification_output_loss: 0.0275 - val_regression_output_loss: 1219.8961 - val_classification_output_accuracy: 0.4270 - val_regression_output_mae: 23.9855\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 1392.0601 - classification_output_loss: 0.4170 - regression_output_loss: 1391.5905 - classification_output_accuracy: 0.5049 - regression_output_mae: 25.3349 - val_loss: 1338.0264 - val_classification_output_loss: 0.0226 - val_regression_output_loss: 1337.9509 - val_classification_output_accuracy: 0.4270 - val_regression_output_mae: 25.5123\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 1327.5740 - classification_output_loss: 0.7584 - regression_output_loss: 1326.7627 - classification_output_accuracy: 0.4726 - regression_output_mae: 25.2052 - val_loss: 1156.2423 - val_classification_output_loss: 0.0226 - val_regression_output_loss: 1156.1670 - val_classification_output_accuracy: 0.4270 - val_regression_output_mae: 23.6504\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 1370.4360 - classification_output_loss: 0.5557 - regression_output_loss: 1369.8274 - classification_output_accuracy: 0.4754 - regression_output_mae: 25.6135 - val_loss: 1318.0854 - val_classification_output_loss: 0.0265 - val_regression_output_loss: 1318.0063 - val_classification_output_accuracy: 0.4270 - val_regression_output_mae: 25.5021\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 1318.2432 - classification_output_loss: 0.3639 - regression_output_loss: 1317.8264 - classification_output_accuracy: 0.4909 - regression_output_mae: 25.2612 - val_loss: 1256.5681 - val_classification_output_loss: 0.0227 - val_regression_output_loss: 1256.4926 - val_classification_output_accuracy: 0.4270 - val_regression_output_mae: 24.4822\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 1144.1633 - classification_output_loss: 0.2407 - regression_output_loss: 1143.8696 - classification_output_accuracy: 0.5021 - regression_output_mae: 23.6782 - val_loss: 1151.8483 - val_classification_output_loss: 0.0204 - val_regression_output_loss: 1151.7750 - val_classification_output_accuracy: 0.4270 - val_regression_output_mae: 23.1113\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 1348.0580 - classification_output_loss: 0.4520 - regression_output_loss: 1347.5531 - classification_output_accuracy: 0.4754 - regression_output_mae: 25.8257 - val_loss: 1281.3108 - val_classification_output_loss: 0.0215 - val_regression_output_loss: 1281.2363 - val_classification_output_accuracy: 0.4270 - val_regression_output_mae: 24.8999\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 1152.4402 - classification_output_loss: 0.2420 - regression_output_loss: 1152.1453 - classification_output_accuracy: 0.4951 - regression_output_mae: 23.6944 - val_loss: 1434.3859 - val_classification_output_loss: 0.0257 - val_regression_output_loss: 1434.3070 - val_classification_output_accuracy: 0.4270 - val_regression_output_mae: 25.9201\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 1440.4133 - classification_output_loss: 0.6536 - regression_output_loss: 1439.7064 - classification_output_accuracy: 0.4782 - regression_output_mae: 25.6718 - val_loss: 1522.4540 - val_classification_output_loss: 0.0341 - val_regression_output_loss: 1522.3669 - val_classification_output_accuracy: 0.4270 - val_regression_output_mae: 26.7351\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 1198.2159 - classification_output_loss: 0.6692 - regression_output_loss: 1197.4935 - classification_output_accuracy: 0.4557 - regression_output_mae: 23.5710 - val_loss: 1314.3314 - val_classification_output_loss: 0.0286 - val_regression_output_loss: 1314.2496 - val_classification_output_accuracy: 0.4213 - val_regression_output_mae: 24.2878\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 1337.4003 - classification_output_loss: 0.7879 - regression_output_loss: 1336.5591 - classification_output_accuracy: 0.4627 - regression_output_mae: 24.4609 - val_loss: 1178.8170 - val_classification_output_loss: 0.0180 - val_regression_output_loss: 1178.7457 - val_classification_output_accuracy: 0.4270 - val_regression_output_mae: 24.0707\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 1191.4348 - classification_output_loss: 0.3770 - regression_output_loss: 1191.0045 - classification_output_accuracy: 0.4768 - regression_output_mae: 24.0241 - val_loss: 1337.9462 - val_classification_output_loss: 0.0326 - val_regression_output_loss: 1337.8602 - val_classification_output_accuracy: 0.4326 - val_regression_output_mae: 25.0691\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 991.8286 - classification_output_loss: 0.6507 - regression_output_loss: 991.1244 - classification_output_accuracy: 0.4796 - regression_output_mae: 21.6016 - val_loss: 1384.9873 - val_classification_output_loss: 0.0363 - val_regression_output_loss: 1384.8973 - val_classification_output_accuracy: 0.4494 - val_regression_output_mae: 25.2290\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 1029.7469 - classification_output_loss: 0.2343 - regression_output_loss: 1029.4592 - classification_output_accuracy: 0.4880 - regression_output_mae: 22.4947 - val_loss: 1197.9287 - val_classification_output_loss: 0.0249 - val_regression_output_loss: 1197.8501 - val_classification_output_accuracy: 0.4494 - val_regression_output_mae: 23.4606\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 1076.1132 - classification_output_loss: 0.3800 - regression_output_loss: 1075.6793 - classification_output_accuracy: 0.5063 - regression_output_mae: 22.5628 - val_loss: 1192.9606 - val_classification_output_loss: 0.0310 - val_regression_output_loss: 1192.8759 - val_classification_output_accuracy: 0.4663 - val_regression_output_mae: 22.9141\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 995.8004 - classification_output_loss: 0.2893 - regression_output_loss: 995.4573 - classification_output_accuracy: 0.5331 - regression_output_mae: 21.6180 - val_loss: 1216.1589 - val_classification_output_loss: 0.0375 - val_regression_output_loss: 1216.0676 - val_classification_output_accuracy: 0.4382 - val_regression_output_mae: 22.6272\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(patience = 10, restore_best_weights=True)\n",
    "#lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=4, verbose=1, min_lr=1e-6)\n",
    "\n",
    "model_3 = conditional_regression_model_1()\n",
    "\n",
    "history = model_3.fit(\n",
    "    x=X_train_preprocessed,\n",
    "    y={'classification_output': y_train_p, 'regression_output': y_train_dates},\n",
    "    validation_split = 0.2,\n",
    "    shuffle = True,\n",
    "    batch_size=32,\n",
    "    epochs = 50,\n",
    "    callbacks = [es],\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 5ms/step - loss: 994.1597 - classification_output_loss: 0.0510 - regression_output_loss: 994.0558 - classification_output_accuracy: 0.5336 - regression_output_mae: 22.1228\n"
     ]
    }
   ],
   "source": [
    "evaluation_3 = model_3.evaluate(\n",
    "    x=X_test_preprocessed,  # Test input data\n",
    "    y={'classification_output': y_test_p, 'regression_output': y_test_dates},  # Dictionary of test labels\n",
    "    verbose=1  # Set to 1 for progress updates during evaluation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bool",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
