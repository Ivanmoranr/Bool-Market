{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-01 17:22:28.817815: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-01 17:22:28.819276: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-01 17:22:28.847182: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-01 17:22:28.847921: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-01 17:22:29.411243: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from synthetic_data import *\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from get_real_data import *\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Masking, Conv1D, Flatten, MaxPooling1D\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ris_wedg, y_ris_wedg, X_fal_wedg, y_fal_wedg, X_d_top, y_d_top, X_d_bottom, y_d_bottom = get_X_y(noise=False, general=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rw_noise, y_rw_noise, X_fw_noise, y_fw_noise, X_dt_noise, y_dt_noise, X_db_noise, y_db_noise = get_hack_noise(X_ris_wedg, y_ris_wedg, X_fal_wedg, y_fal_wedg, X_d_top, y_d_top, X_d_bottom, y_d_bottom, synth=True, real=True, f=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_synth = X_ris_wedg + X_rw_noise + X_fal_wedg + X_fw_noise + X_d_top + X_dt_noise + X_d_bottom + X_db_noise\n",
    "y_synth = y_ris_wedg + y_rw_noise + y_fal_wedg + y_fw_noise + y_d_top + y_dt_noise + y_d_bottom + y_db_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, y1, X2, y2, X3, y3, X4, y4 = get_real_X_y()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_noise, y1_noise, X2_noise, y2_noise, X3_noise, y3_noise, X4_noise, y4_noise = get_hack_noise(X1, y1, X2, y2, X3, y3, X4, y4, synth=False, real=True, f=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_up, y_up, X_down, y_down = get_up_down(patterns=[\"uptrend\",\"downtrend\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_real = X1 + X1_noise + X2 + X2_noise + X3 + X3_noise + X4 + X4_noise + X_up + X_down\n",
    "y_real = y1 + y1_noise + y2 + y2_noise + y3 + y3_noise + y4 + y4_noise + y_up + y_down\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_real + X_synth\n",
    "y = y_real + y_synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehotencode(y_synth):\n",
    "    y_synth = np.array(y_synth)\n",
    "    start = y_synth[:,0]\n",
    "    end = y_synth[:,1]\n",
    "    pattern = y_synth[:,2]\n",
    "    mapping = {\n",
    "        0: [0, 0, 0, 0],\n",
    "        1: [0, 0, 0, 1],\n",
    "        2: [0, 0, 1, 0],\n",
    "        3: [0, 1, 0, 0],\n",
    "        4: [1, 0, 0, 0]\n",
    "    }\n",
    "    mapped_values = [tuple(mapping[val]) for val in pattern]\n",
    "    y_s = list(np.column_stack((start, end, mapped_values)))\n",
    "    return y_s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preprocessed = onehotencode(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_preprocessed = pad_sequences(X, dtype='float32', padding='post', value=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = X_train[:,:,0]\n",
    "z = X_train[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2446748"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y_preprocessed, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_scaler = StandardScaler()\n",
    "X_o_train = open_scaler.fit_transform(X_train[:,:,0])\n",
    "X_o_test = open_scaler.transform(X_test[:,:,0])\n",
    "high_scaler = StandardScaler()\n",
    "X_h_train = high_scaler.fit_transform(X_train[:,:,1])\n",
    "X_h_test = high_scaler.transform(X_test[:,:,1])\n",
    "low_scaler = StandardScaler()\n",
    "X_l_train = low_scaler.fit_transform(X_train[:,:,2])\n",
    "X_l_test = low_scaler.transform(X_test[:,:,2])\n",
    "close_scaler = StandardScaler()\n",
    "X_c_train = close_scaler.fit_transform(X_train[:,:,3])\n",
    "X_c_test = close_scaler.transform(X_test[:,:,3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_o_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m X_train_preprocessed \u001b[39m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m X_test_preprocessed \u001b[39m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X_o_train)):\n\u001b[1;32m      4\u001b[0m     X_train_preprocessed\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39mcolumn_stack((X_o_train, X_h_train, X_l_train, X_c_train)))\n\u001b[1;32m      5\u001b[0m     X_test_preprocessed\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39mcolumn_stack((X_o_test, X_h_test, X_l_test, X_c_test)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_o_train' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_preprocessed = []\n",
    "X_test_preprocessed = []\n",
    "for i in range(len(X_o_train)):\n",
    "    X_train_preprocessed.append(np.column_stack((X_o_train, X_h_train, X_l_train, X_c_train)))\n",
    "    X_test_preprocessed.append(np.column_stack((X_o_test, X_h_test, X_l_test, X_c_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have to change with the functional api, because is a two problem one for regresion and other for classification\n",
    "\n",
    "### We have to add an intermediate layer\n",
    "\n",
    "### Look into generative models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_preprocessed = tf.convert_to_tensor(X_train_preprocessed, np.float32)\n",
    "y_train = tf.convert_to_tensor(y_train, np.int16)\n",
    "\n",
    "display(type(X_train_preprocessed))\n",
    "display(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train_preprocessed.shape[1:]\n",
    "\n",
    "def initialize_model_CNN():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Masking(mask_value=-1, input_shape=input_shape))\n",
    "    model.add(Conv1D(32, activation='relu', kernel_size=3, kernel_regularizer=regularizers.L1L2(l1=1e-3, l2=1e-3))),\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(32, activation='relu', kernel_size=3))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=200, activation='relu'))\n",
    "    model.add(Dense(units=100, activation='relu'))\n",
    "    model.add(Dense(units=16, activation='relu'))\n",
    "    model.add(Dense(units=16, activation='relu'))\n",
    "    model.add(Dense(units=3, activation='linear'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(patience = 5, restore_best_weights=True)\n",
    "\n",
    "model = initialize_model_CNN()\n",
    "\n",
    "model.fit(\n",
    "    X_train_preprocessed,\n",
    "    y_train,\n",
    "    validation_split = 0.2,\n",
    "    shuffle = True,\n",
    "    batch_size=32,\n",
    "    epochs = 50,\n",
    "    callbacks = [es],\n",
    "    verbose = 1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bool",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
